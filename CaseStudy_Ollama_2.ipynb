{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1Pl5qn6OXAt"
   },
   "outputs": [],
   "source": [
    "%pip install transformers langdetect deep-translator torch torchvision torchaudio langchain langchain-community langchain-ollama gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQAZeuXwPeh8"
   },
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OoZB4EXPwFd"
   },
   "outputs": [],
   "source": [
    "model_name = \"mistral\"\n",
    "llm = ChatOllama(\n",
    "    temperature = 0,\n",
    "    max_tokens = 2000,\n",
    "    model = model_name\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "You're a native internal AI assistant. Help users with their important tasks, like a professor in a particular field.\n",
    "\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"query\"],\n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkqalPydP_Yo"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evkhR_yfQCj5"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "class Translation:\n",
    "  def __init__(self, text, destination):\n",
    "    self.text = text\n",
    "    self.destination = destination\n",
    "\n",
    "    try:\n",
    "      self.original = detect(self.text)\n",
    "    except Exception as error:\n",
    "      print(f\"Error Occurred, Details : {error}\")\n",
    "      self.original = \"auto\"\n",
    "\n",
    "  def translate(self):\n",
    "    translator = GoogleTranslator(source=self.original, target=self.destination)\n",
    "    translation = translator.translate(self.text)\n",
    "\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdsfwKKHQd0u"
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBkzyXoIQhhu"
   },
   "outputs": [],
   "source": [
    "def reply(message, history):\n",
    "  txt = Translation(message, \"en\")\n",
    "\n",
    "  if txt.original == \"en\":\n",
    "    response = chain.invoke({\n",
    "        \"query\": message\n",
    "    })\n",
    "\n",
    "    return response\n",
    "  else:\n",
    "    translation = txt.translate()\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"query\": translation\n",
    "    })\n",
    "\n",
    "    t = Translation(response.content, txt.original)\n",
    "    final_response = t.translate()\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgALjhwLUIMH"
   },
   "outputs": [],
   "source": [
    "question = \"What is Deep Learning?\"\n",
    "\n",
    "result = reply(question, history = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CD6tqsjCUTCY"
   },
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "mz-iahXfUcb6",
    "outputId": "ccca31d7-1473-48e4-89eb-b3da31f7b43d"
   },
   "outputs": [],
   "source": [
    "question = \"ரியல் எஸ்டேட்டில் அதிக பணம் சம்பாதிப்பது எப்படி?\"\n",
    "\n",
    "result = reply(question, history = [])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHMFc4K3REga"
   },
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(fn=reply, title = \"Multi-Lingual ChatBot\")\n",
    "\n",
    "demo.launch(debug=False, share=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
